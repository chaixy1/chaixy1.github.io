---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Xinyue Chai is a student in Tsinghua University and a desinger.He received his Bachelor of Engineering degree from [Nanjing University of Aeronautics and Astronautics](https://www.nuaa.edu.cn/) in 2022 and was admitted to [Tsinghua University](https://www.tsinghua.edu.cn/) in 2023, where he is currently enrolled in the Interactive Media Design and Technology program. 

[CV](https://drive.google.com/file/d/16gN7BkS5ygCLh719qNcswiJOYEYGaibo/view?usp=sharing)

Research Interests:
- Soft Robotics ApplicationsÔºàSmart Clothing Design & Haptic RenderingÔºâ
- LLM-based Collaboration in Socially Marginalized CommunitiesÔºàSocial Inclusion & Empowerment through Technology üåàÔºâ
- Serious Games

# üî• News
- *2024.06.02 - 2024.06.07* üéâüéâ [Workshop on Future Smart Wearable Haptic Fabrics](https://mp.weixin.qq.com/s/FypWLLu8GB5rYkXjqi0klA) at Tsinghua University's Future Laboratory 

# üìñ Educations
- *2023.09 - 2026.06 (expected)*, Tsinghua University, Interactive Media Design and Technology. 
- *2018.09 - 2022.06*, Nanjing University of Aeronautics and Astronautics, Information Engineering.

# üéñ Honors and Awards
- *2022.06* First Prize of Nanjing University of Aeronautics and Astronautics School-level Excellent Thesis
- *2021.05* Provincial Second Prize of the 17th Challenge Cup Extracurricular Academic Works Competition for Undergraduates
- *2020.11* National Inspiration Scholarship of the People's Republic of China
- *2019.11* National Scholarships of the People's Republic of China 

# üíª Interactive Design Works

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Virbot</div><img src='images/Virbot.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**VibroBot: A Wearable and Programmable Vibration Bot for Multichannel Tactile Guidance**

**Submission in progress, for details, you can contact by mail**

**Introduction** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
VibroBot is an innovative tactile interaction device designed to provide unique user experiences through multichannel tactile feedback. Each VibroBot weighs just 2.9 grams, making it lightweight yet powerful. It uses wireless communication to receive programmable signals, delivering six distinguishable vibration feedback patterns in real-time to guide precise finger movements. When worn on all five fingers, VibroBot works collaboratively to help users adjust each finger, achieving perfect hand gesture control. With VibroBot's guidance, users can perform accurate grabbing actions in virtual environments, correct gesture errors, and improve operational precision and efficiency.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">HapNav</div><img src='images/HapNav.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**HapNav: Design of Smart Navigation Wristband Based on Pneumatic Haptic Feedback**

[**Project**](https://www.youtube.com/watch?v=JDz-a6aVFpo)

**Introduction** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
When using cell phone navigation in daily life, there may be a lot of inconvenience in using cell phone navigation in the scenarios such as cycling, driving, and traveling for people with sensory disabilities due to hand occupancy or limited access to the audiovisual senses. Therefore, we have developed this smart wearable wristband for the limited access to audio-visual senses, which utilizes the sense of touch for navigation. The feedback form is pneumatic, and different forms of airbag structures can be designed to produce different tactile experiences. The fabric is made of wool knit, which allows us to quickly design different styles and customize different colors and patterns in a short period of time.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='images/master22.png' alt="sym" width="100%"><img src='images/master11.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Training Master : Reinforcement Learning Science Game Based On Unity3D Game Engine**

**Introduction** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
Master Trainer is a sci-fi game of Artificial Intelligence and Reinforcement Learning. Players need to observe the different environments of each level and give commands to their pets according to the prompts. And the pet will follow the underlying logic of reinforcement learning and react accordingly to the player's instructions. It may be able to successfully accomplish the goal, or it may be very different from the trainer's original intention. We hope that the player will be able to subconsciously understand the concepts of action, environment, and reward in reinforcement learning. The game is developed based on Unity3D and the game is pre-trained using the [PPO algorithm](https://en.wikipedia.org/wiki/Proximal_policy_optimization).
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='images/Lily.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Lily's Night ÔºöArduino Sensor-based Somatosensory Games**

[**Project**](https://www.bilibili.com/video/BV1Pa4y1f7C8/?spm_id_from=333.999.0.0&vd_source=3fe344ae0b27126cbc716211cffe4197)

**Introduction** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
"Lily's Night" is a sensor game based on Arduino ultrasonic, the game is about a young man named Lily, in an attempt to jump off a building to commit suicide, from the heart burst out of the desire to survive, the player plays the falling Lily, through the climb to obtain the possibility of survival. The game aims to urge people to care more about their own mental health as well as those around them. The game is developed based on Unity3D game engine and [Arduino ultrasonic sensor](https://projecthub.arduino.cc/Isaac100/getting-started-with-the-hc-sr04-ultrasonic-sensor-7cabe1).
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div><img src='images/Light.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Lights On ÔºöMultiplayer Decryption Game Online**

[**Project**](https://www.bilibili.com/video/BV11G411D7GK/?spm_id_from=333.999.0.0&vd_source=3fe344ae0b27126cbc716211cffe4197)

**Introduction** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
"Lights On" is a multiplayer online puzzle game set in a mysterious world where two players enter parallel paths to explore and solve puzzles. Each path has its own unique environment and challenges. The paths are filled with lampposts and other mechanisms, and the two players work together to break through them. This project is developed based on Unity3D and Lua language.
</div>
</div>

<div class='paper-box'>
  <div class='paper-box-image'>
    <div><div class="badge"></div>
      <video width="100%" controls>
        <source src='images/Canves2.mp4' type='video/mp4'>
        Your browser does not support the video tag.
      </video>
    </div>
    <div><div class="badge"></div>
      <video width="100%" controls>
        <source src='images/Canves3.mp4' type='video/mp4'>
        Your browser does not support the video tag.
      </video>
    </div>
  </div>
<div class='paper-box-text' markdown="1">

**Draw And Play ÔºöInteractive Drawing Educational Tools**

**Introduction** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
"Draw And Play" is an interactive game for children's drawing education. Existing drawing education emphasizes on color matching and drawing skills. In order to stimulate children's higher interest in drawing, this interactive game is developed, where children can use brushes to draw on the computer, and then based on the camera's motion capture, children can interact with the handwriting, which will stimulate more creativity. The project is developed based on Unity game engine and Mediapipe framework.

ÔºàüëàThe video has no sound, it's not a playback problem on your computer üòâÔºâ
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"></div>
      <video width="100%" controls>
        <source src='images/robotarm.mp4' type='video/mp4'>
        Your browser does not support the video tag.
      </video></div></div>
<div class='paper-box-text' markdown="1">

**Remote Operation System of Robotic Arm Based On Inertial Motion-capture Gloves**

**Introduction** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
This project focuses on developing a remote operation system for a robotic arm, leveraging the capabilities of [MANUS motion capture gloves](https://www.manus-meta.com/) and a Realsense camera. The system captures the position and rotation information of the gloves through the [Realsense](https://www.intel.com/content/www/us/en/architecture-and-technology/realsense-overview.html) camera, enabling precise control of the robotic arm's end effector. Additionally, the bending information from the motion capture gloves is used to control the finger movements of the robotic hand, allowing for intricate and accurate remote grasping and manipulation tasks.By integrating these advanced technologies, the system provides a seamless interface for operators to perform complex tasks from a distance, enhancing precision and efficiency in remote environments.

ÔºàüëàThe video has no sound, it's not a playback problem on your computer üòâÔºâ
</div>
</div>

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CIEEC 2022</div><img src='images/Â±èÂπïÊà™Âõæ 2024-05-27 190655.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**A DDQN-based Energy-Efficient Resource Allocation Scheme for Low-Latency V2V communication**

Juanjuan Miao, **Xinyue Chai**, Xiaoqin Song, Tiechen Song

[**Project**](https://ieeexplore.ieee.org/document/9846189)

**Abstract** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
This paper examines sidelink (SL) resource allocation for the new radio vehicle-to-everything (NR-V2X) technology based on 5G networks, focusing on Vehicle-to-Vehicle (V2V) communication outside the coverage of 5G base stations. Using network slicing technology, V2V sidelinks utilize spectrum designated for ultra-reliable and low-latency communications (URLLC). To enhance energy efficiency and meet URLLC delay requirements, we propose a deep reinforcement learning (DRL) architecture with centralized training and distributed execution. A model using Double Deep Q-Network (DDQN) is trained to achieve these goals. Simulations show that our DDQN-based algorithm performs better in terms of energy efficiency and latency compared to other algorithms.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICSIP 2021</div><img src='images/Â±èÂπïÊà™Âõæ 2024-05-27 192707.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Deep Q-learning Enabled Wireless Resource Allocation for 5G Network Based Vehicle-to-vehicle Communications**

Shumo Wang, **Xinyue Chai**, Xiaoqin Song, Xin Liang

[**Project**](https://ieeexplore.ieee.org/document/9689007)

**Abstract** <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
Vehicle-to-vehicle (V2V) communication is essential for intelligent transportation systems (ITS), requiring effective cooperation among vehicles. The main challenge is ensuring reliable transmission under latency conditions. This paper explores wireless resource allocation for 5G-based V2V communication, using network slicing to differentiate between V2V and vehicle-to-infrastructure (V2I) links. Formulating reliable transmission and latency constraints into optimization problems is difficult, so we use deep Q-learning for resource allocation. In our framework, each V2V link acts as an agent, learning to select sub-channels and transmission power through a designed reward system and training mechanism. Simulations show that V2V links can ensure successful message transmission while maximizing overall capacity.
</div>
</div>
